{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from imutils import paths\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "import cv2\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMG_DIMS = (224, 224, 3)\n",
    "\n",
    "MODEL_NAME = \"multi-class\"\n",
    "\n",
    "data_set_dir = 'data/dataset/' + MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_set(directory):\n",
    "    \n",
    "    classifiers = next(os.walk(data_set_dir))[1]\n",
    "    \n",
    "    print(\"[INFO] loading images from {}\".format(directory))\n",
    "    # initialize the data and labels\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # grab the image paths and randomly shuffle them\n",
    "    image_paths = sorted(list(paths.list_images(directory)))\n",
    "    random.seed(42)\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    # loop over the input images\n",
    "    for image_path in image_paths:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (IMG_DIMS[1], IMG_DIMS[0]))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    " \n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list        \n",
    "        l = label = image_path.split(os.path.sep)[-2].split(\"-\")\n",
    "        labels.append(l)\n",
    "        \n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    print(\"[INFO] Labels\")\n",
    "    print(labels)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    \n",
    "    # loop over each of the possible class labels and show them\n",
    "    print(\"[INFO] Classifiers\")\n",
    "    for (i, label) in enumerate(mlb.classes_):\n",
    "        print(\"{}. {}\".format(i + 1, label))\n",
    "    \n",
    "    classifiers = mlb.classes_\n",
    "    \n",
    "    print(\"[INFO] Splitting the Train and Test sets\")\n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(data,\n",
    "                                                        labels,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "#     train_Y = to_categorical(train_Y, num_classes=NUM_OF_CLASSES)\n",
    "#     test_Y = to_categorical(test_Y, num_classes=NUM_OF_CLASSES)\n",
    "\n",
    "    return train_X, test_X, train_Y, test_Y, classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_performance_graph(model, epochs):\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = epochs\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"loss\"], \n",
    "             label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"val_loss\"], \n",
    "             label=\"val_loss\")\n",
    "    \n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"acc\"], \n",
    "             label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"val_acc\"], \n",
    "             label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_of_classes):\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=IMG_DIMS)\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    \n",
    "    preds = Dense(num_of_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(input=base_model.input, outputs=preds)\n",
    "    \n",
    "    for layer in model.layers[:20]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[20:]:\n",
    "        layer.trainable=True\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset_dir):\n",
    "    train_X, test_X, train_Y, test_Y, classifiers = split_train_test_set(dataset_dir)\n",
    "    \n",
    "    print(\"[INFO] Augmenting image data...\")\n",
    "    # construct the image generator for data augmentation\n",
    "    aug = ImageDataGenerator(rotation_range=25, \n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode=\"nearest\")\n",
    "    \n",
    "    # initialize the model\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    \n",
    "    model = build_model(len(classifiers))\n",
    "                  \n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=opt, \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    H = model.fit_generator(\n",
    "        aug.flow(train_X, train_Y, batch_size=BS),\n",
    "        validation_data=(test_X, test_Y), \n",
    "        steps_per_epoch=len(train_X) // BS,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1)\n",
    "    # save the model to disk\n",
    "    print(\"[INFO] serializing network...\")\n",
    "    model.save(MODEL_NAME + \"_model.h5\")\n",
    "    print(\"[INFO] serializing label binarizer...\")\n",
    "    \n",
    "    with open(MODEL_NAME + '_labels.json', 'w') as f:\n",
    "        for classify in classifiers:\n",
    "            f.write(classify + '\\n')\n",
    "    \n",
    "    return H, model, classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images from data/dataset/multi-class\n"
     ]
    }
   ],
   "source": [
    "h, model, classifiers = train_model(data_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_performance_graph(h, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "image = cv2.imread('./test3.jpg')\n",
    "orig = image.copy()\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (IMG_DIMS[0], IMG_DIMS[1]))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (label, p) in zip(classifiers, predictions):\n",
    "    print(\"{}: {:.2}%\".format(label, p * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, MODEL_NAME + \"_tfjs_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
