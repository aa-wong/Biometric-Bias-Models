{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_model(img_dims, classes):\n",
    "    # Initialize the model\n",
    "    model = Sequential()\n",
    "    input_shape = (img_dims[1], \n",
    "                   img_dims[0], \n",
    "                   img_dims[2])\n",
    "    chan_dim = -1\n",
    "    \n",
    "    # Update input_shape if using channels_first\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        input_shape = (img_dims[2], \n",
    "                       img_dims[1], \n",
    "                       img_dims[0])\n",
    "        chan_dim = 1\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), input_shape=input_shape))\n",
    "    model.add(Conv2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "    model.add(Conv2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(4096, 7, 7, activation='relu', name='fc6'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(4096, 1, 1, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(classes, 1, 1, name='fc8'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # return the constructed network architecture\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "EPOCHS = 75\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMG_DIMS = (224, 224, 3)\n",
    "\n",
    "MODEL_NAME = \"gender\"\n",
    "\n",
    "data_set_dir = 'data/dataset/' + MODEL_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_set(directory):\n",
    "    \n",
    "    classifiers = next(os.walk(data_set_dir))[1]\n",
    "    \n",
    "    print(\"[INFO] loading images from {}\".format(directory))\n",
    "    # initialize the data and labels\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # grab the image paths and randomly shuffle them\n",
    "    image_paths = sorted(list(paths.list_images(directory)))\n",
    "    random.seed(42)\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    # loop over the input images\n",
    "    for image_path in image_paths:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (IMG_DIMS[0], IMG_DIMS[1]))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    " \n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list        \n",
    "        label = image_path.split(os.path.sep)[-2]\n",
    "        l = classifiers.index(label)\n",
    "        labels.append(l)\n",
    "        \n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "    labels = np.array(labels)\n",
    "     \n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(data,\n",
    "                                                        labels,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42)\n",
    " \n",
    "    # convert the labels from integers to vectors\n",
    "    train_Y = to_categorical(train_Y, num_classes=2)\n",
    "    test_Y = to_categorical(test_Y, num_classes=2)\n",
    "    \n",
    "    return train_X, test_X, train_Y, test_Y, classifiers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_performance_graph(model):\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"loss\"], \n",
    "             label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"val_loss\"], \n",
    "             label=\"val_loss\")\n",
    "    \n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"acc\"], \n",
    "             label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"val_acc\"], \n",
    "             label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset_dir):\n",
    "    train_X, test_X, train_Y, test_Y, classifiers = split_train_test_set(dataset_dir)\n",
    "    \n",
    "    # initialize the model\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model = binary_model(IMG_DIMS, classes=2)\n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=opt, \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    # construct the image generator for data augmentation\n",
    "    aug = ImageDataGenerator(rotation_range=30, \n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode=\"nearest\")\n",
    "    \n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    h = model.fit_generator(\n",
    "        aug.flow(train_X, train_Y, batch_size=BS),\n",
    "        validation_data=(test_X, test_Y), \n",
    "        steps_per_epoch=len(train_X) // BS,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1)\n",
    "    # save the model to disk\n",
    "    print(\"[INFO] serializing network...\")\n",
    "    model.save(MODEL_NAME + \"_model.h5\")\n",
    "    return h, model, classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images from data/dataset/gender\n"
     ]
    }
   ],
   "source": [
    "h, model, classifiers = train_model(data_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_performance_graph(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = binary_model(IMG_DIMS, classes=2)\n",
    "# model.load_weights(\"./gender_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "image = cv2.imread('./test5.jpg')\n",
    "orig = image.copy()\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (IMG_DIMS[0], IMG_DIMS[1]))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(classifiers):\n",
    "    print(\"{}: {:.2}%\".format(label, prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
