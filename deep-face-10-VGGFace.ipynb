{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from imutils import paths\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "import cv2\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "EPOCHS = 10\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMG_DIMS = (224, 224, 3)\n",
    "\n",
    "MODEL_NAME = \"multi-class\"\n",
    "\n",
    "data_set_dir = 'data/dataset/' + MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_set(directory):\n",
    "    \n",
    "    classifiers = next(os.walk(data_set_dir))[1]\n",
    "    \n",
    "    print(\"[INFO] loading images from {}\".format(directory))\n",
    "    # initialize the data and labels\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # grab the image paths and randomly shuffle them\n",
    "    image_paths = sorted(list(paths.list_images(directory)))\n",
    "    random.seed(42)\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    # loop over the input images\n",
    "    for image_path in image_paths:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (IMG_DIMS[1], IMG_DIMS[0]))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    " \n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list        \n",
    "        l = label = image_path.split(os.path.sep)[-2].split(\"-\")\n",
    "        labels.append(l)\n",
    "        \n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    print(\"[INFO] Labels\")\n",
    "    print(labels)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    \n",
    "    # loop over each of the possible class labels and show them\n",
    "    print(\"[INFO] Classifiers\")\n",
    "    for (i, label) in enumerate(mlb.classes_):\n",
    "        print(\"{}. {}\".format(i + 1, label))\n",
    "    \n",
    "    classifiers = mlb.classes_\n",
    "    \n",
    "    print(\"[INFO] Splitting the Train and Test sets\")\n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(data,\n",
    "                                                        labels,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "#     train_Y = to_categorical(train_Y, num_classes=NUM_OF_CLASSES)\n",
    "#     test_Y = to_categorical(test_Y, num_classes=NUM_OF_CLASSES)\n",
    "\n",
    "    return train_X, test_X, train_Y, test_Y, classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_performance_graph(model, epochs):\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = epochs\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"loss\"], \n",
    "             label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"val_loss\"], \n",
    "             label=\"val_loss\")\n",
    "    \n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"acc\"], \n",
    "             label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), \n",
    "             model.history[\"val_acc\"], \n",
    "             label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_of_classes):\n",
    "    base_model = VGGFace(include_top=False, input_shape=IMG_DIMS)\n",
    "    \n",
    "    x = base_model.get_layer('pool5').output\n",
    "    x = Flatten(name='flatten')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    x = Dense(512, activation='relu', name='fc6')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    x = Dense(512, activation='relu', name='fc7')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    preds = Dense(num_of_classes, activation='softmax', name='fc8')(x)\n",
    "    model = Model(input=base_model.input, outputs=preds)\n",
    "    \n",
    "    for layer in model.layers[:-7]:\n",
    "        layer.trainable=False\n",
    "#     for layer in model.layers[20:]:\n",
    "#         layer.trainable=True\n",
    "    # Check the trainable status of the individual layers\n",
    "    for layer in model.layers:\n",
    "        print(layer, layer.trainable)\n",
    "        \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset_dir):\n",
    "    train_X, test_X, train_Y, test_Y, classifiers = split_train_test_set(dataset_dir)\n",
    "    \n",
    "    print(\"[INFO] Augmenting image data...\")\n",
    "    # construct the image generator for data augmentation\n",
    "    aug = ImageDataGenerator(rotation_range=25, \n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode=\"nearest\")\n",
    "    \n",
    "    # initialize the model\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    \n",
    "    model = build_model(len(classifiers))\n",
    "                  \n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=opt, \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    H = model.fit_generator(\n",
    "        aug.flow(train_X, train_Y, batch_size=BS),\n",
    "        validation_data=(test_X, test_Y), \n",
    "        steps_per_epoch=len(train_X) // BS,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1)\n",
    "    \n",
    "    # serialize model to JSON\n",
    "    print(\"[INFO] Serialize network model to JSON...\")\n",
    "    model_json = model.to_json()\n",
    "    with open(MODEL_NAME + '_keras_model.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    # save the model to disk\n",
    "    print(\"[INFO] serializing network...\")\n",
    "    model.save(MODEL_NAME + \"_model.h5\")\n",
    "    print(\"[INFO] serializing label binarizer...\")\n",
    "    \n",
    "    with open(MODEL_NAME + '_labels.json', 'w') as f:\n",
    "        for classify in classifiers:\n",
    "            f.write(classify + '\\n')\n",
    "    \n",
    "    return H, model, classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images from data/dataset/multi-class\n",
      "[INFO] Labels\n",
      "[['happy_high' 'male']\n",
      " ['attractive_medium' 'male']\n",
      " ['attractive_low' 'male']\n",
      " ...\n",
      " ['attractive_high' 'male']\n",
      " ['attractive_non' 'female']\n",
      " ['trustworthy_low' 'female']]\n",
      "[INFO] Classifiers\n",
      "1. attractive_high\n",
      "2. attractive_low\n",
      "3. attractive_medium\n",
      "4. attractive_non\n",
      "5. female\n",
      "6. happy_high\n",
      "7. happy_low\n",
      "8. happy_medium\n",
      "9. happy_non\n",
      "10. male\n",
      "11. sad_high\n",
      "12. sad_low\n",
      "13. sad_medium\n",
      "14. sad_non\n",
      "15. threatening_high\n",
      "16. threatening_low\n",
      "17. threatening_medium\n",
      "18. threatening_non\n",
      "19. trustworthy_high\n",
      "20. trustworthy_low\n",
      "21. trustworthy_medium\n",
      "22. trustworthy_non\n",
      "[INFO] Splitting the Train and Test sets\n",
      "[INFO] Augmenting image data...\n",
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From /Users/Aaron/miniconda3/envs/vggfacekeras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1259: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "<keras.engine.topology.InputLayer object at 0x108a9f518> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c3247a6a0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c3247ae48> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x1c84e9e208> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c3254f320> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c3256dfd0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x1c84ef75c0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c84f15400> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c3250a588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c3250af98> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x1c324c7860> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c324ed518> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c3c9c47b8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c3c9f09e8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x1c3c9f0fd0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c7016ce80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c7018bd30> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x1ca3875518> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x1cbc44e6a0> True\n",
      "<keras.layers.core.Flatten object at 0x1c54223860> True\n",
      "<keras.layers.core.Dense object at 0x1c54223a58> True\n",
      "<keras.layers.core.Dense object at 0x1c542400b8> True\n",
      "<keras.layers.core.Dense object at 0x1c33ab60b8> True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 22)                11286     \n",
      "=================================================================\n",
      "Total params: 27,834,198\n",
      "Trainable params: 17,839,126\n",
      "Non-trainable params: 9,995,072\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/Aaron/miniconda3/envs/vggfacekeras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Aaron/miniconda3/envs/vggfacekeras/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"fc..., inputs=Tensor(\"in...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a74c5893f084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "h, model, classifiers = train_model(data_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_performance_graph(h, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "image = cv2.imread('./test2.jpg')\n",
    "orig = image.copy()\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (IMG_DIMS[0], IMG_DIMS[1]))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (label, p) in zip(classifiers, predictions):\n",
    "    print(\"{}: {:.2}%\".format(label, p * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, MODEL_NAME + \"_tfjs_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
